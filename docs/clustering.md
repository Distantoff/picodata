# Общая схема инициализации кластера
Данный раздел содержит описание архитектуры Picodata, в том числе высокоуровневый процесс инициализации кластера на основе нескольких отдельно запущенных экземпляров Picodata (инстансов).

Администратор запускает несколько инстансов, передавая в качестве аргументов необходимые параметры:

```sh
picodata run --instance-id i1 --listen i1 --peer i1,i2,i3
picodata run --instance-id i2 --listen i2 --peer i1,i2,i3
picodata run --instance-id i3 --listen i3 --peer i1,i2,i3
# ...
picodata run --instance-id iN --listen iN --peer i1
```

Независимо от количества запускаемых инстансов, в опции `--peer` у каждого из них следует указать один и тот же набор из нескольких инстансов — одного обычно достаточно, но для подстраховки можно взять три. Именно на их основе будет произведена инициализация кластера и поиск всех работающих инстансов для их включения в состав кластера (discovery).

Подробности алгоритма discovery приведены в отдельном [документе](discovery.md). В контексте сборки кластера важно лишь понимать, что этот алгоритм позволяет не более чем одному инстансу (peer'у) создать Raft-группу, т.е. стать инстансом с raft_id=1. Если таких инстансов будет несколько, то и Raft-групп, а следовательно и кластеров Picodata получится несколько.

Топологией Raft-группы управляет алгоритм Raft, реализованный в виде крейта `raft-rs`.

## Этапы инициализации кластера
На схеме ниже показаны этапы жизненного цикла инстанса в контексте его присоединения к кластеру Picodata.

![main.rs](clustering_curves.svg "main.rs control flow")

Красным показан родительский процесс, который запущен на всем протяжении жизненного цикла инстанса. Вся логика, начиная с присоединения к кластеру, и заканчивая обслуживанием клиентских запросов, происходит в дочернем процессе (голубой цвет). Единственное предназначение родительского процесса — иметь возможность сбросить состояние дочернего (выполнить rebootstrap) и инициализировать его повторно (сиреневый цвет).

Данная схема наиболее полно отражает логику кода в файле `main.rs`. Ниже описаны детали выполнения каждого этапа и соответствующей программной функции.

### fn main()

На этом этапе происходит ветвление (форк) процесса `picodata`. Родительский процесс (supervisor) ожидает от дочернего процесса сообщения по механизму IPC и при необходимости перезапускает дочерний процесс. Также, при необходимости дочерний процесс может попросить родителя удалить все файлы БД, т.е. вызвать функцию `drop_db()`. Это может понадобиться для повторной инициализации кластера когда, например, у инстанса изначально имеется временный, случайно сгенерированный `replicaset_id`.

### fn start_discover()

Дочерний процесс начинает свое существование с запуска модуля `box.cfg()` и вызова функции `start_discover()`. Возможно, что при этом из БД будет ясно, что bootstrap данного инстанса уже был произведен ранее и что Raft уже знает о вхождении этого инстанса в кластер — в таком случае никакого discovery не будет, инстанс сразу перейдет к этапу `postjoin()`. В противном случае, если место инстанса в кластере еще не известно, алгоритм discovery определяет значение флага `i_am_bootstrap_leader` и адрес лидера Raft-группы. Далее инстанс сбрасывает свое состояние (этап rebootstrap), чтобы повторно провести инициализацию `box.cfg()`, теперь уже с известными параметрами. Сам лидер (единственный с `i_am_bootstrap_leader == true`) выполняет функцию `start_boot()`. Остальные инстансы переходят к функции `start_join()`.

### fn start_boot()

В функции `start_boot` происходит инициализация Raft-группы — лидер генерирует и сохраняет в БД первые записи в журнале. Эти записи описывают добавление первого инстанса в пустую Raft-группу. Таким образом достигается однообразие кода, обрабатывающего эти записи.

Сам Raft-узел на данном этапе еще не создается. Это произойдет позже, на стадии `postjoin()`.

### fn start_join()

Вызову функции `start_join()` всегда предшествует rebootstrap (удаление БД и перезапуск процесса), поэтому на данном этапе в БД нет ни модуля box, ни пространства хранения. Функция `start_join()` имеет простое устройство:

Инстанс-клиент отправляет запрос `raft_join` лидеру Raft-группы (он известен после discovery). После достижения консенсуса в Raft-группе лидер присылает в ответе необходимую информацию:
- Идентификатор `raft_id` и данные таблицы `raft_group` — для инициализации Raft-узла;
- Идентификаторы  `instance_uuid`, `replicaset_uuid` и параметры `replication`, `read_only` для `box.cfg`.

Получив все настройки, инстанс использует их в `box.cfg()`, и затем создает в БД группу `raft_group` с актуальными адресами других инстансов. Без этого инстанс не сможет отвечать на  сообщения от других членов Raft-группы. Для того чтобы записи в `raft_group` не были заменены на менее актуальные из журнала Raft, каждая запись маркируется значением `commit_index`.

По завершении этих манипуляций инстанс также переходит к этапу `postjoin()`.

### fn postjoin()

Логика функции `postjoin()` одинакова для всех инстансов. К этому моменту для инстанса уже инициализированы корректные пространства хранения в БД и могут быть накоплены записи в журнале Raft. Инстанс инициализирует узел Raft и проверяет, что данные синхронизированы (`read barrier` получен) и журнал Raft актуален. Из журнала становятся известны параметры репликации, и инстанс начинает синхронизацию данных уровне репликационных групп Tarantool.

Следующим шагом инстансу необходимо актуализировать свой статус (`UpdatePeerRequest{ target_grade: 50_Online, failure_domain }`), и дождаться коммита этой записи в Raft.

Теперь узел Raft готов к использованию.

## Обработка запросов

### \#\[proc\] fn raft_join()

Значительная часть всей логики по управлению топологией находится в хранимой процедуре `raft_join`. Аргументом для нее является следующая структура:

```rust
struct JoinRequest {
    cluster_id: String,
    instance_id: Option<String>,
    replicaset_id: Option<String>,
    advertise_address: String,
    failure_domain: FailureDomain,
}
```

Ответом служит структура:

```rust
struct JoinResponse {
    /// Добавленный пир (чтобы знать все ID)
    peer: Peer,
    /// Голосующие узлы (чтобы добавляемый инстанс мог наладить контакт)
    raft_group: Vec<Peer>,
    /// Настройки репликации (чтобы инициализировать репликацию)
    box_replication: Vec<String>,
}

struct Peer {
    // всевозможные идентификаторы
    raft_id: RaftId,
    instance_id: String,
    instance_uuid: String,
    replicaset_id: String,
    replicaset_uuid: String,

    // текущее местоположение, виртуальное и физическое
    peer_address: String,
    failure_domain: FailureDomain,

    /// 0_Offline (current / target)
    /// 10_RaftSynced (current)
    /// 20_BoxSynced (current)
    /// 30_VshardInitialized (current)
    /// 50_Online (current / target)
    /// 60_Expelled (current / target)
    target_grade: Grade,
    current_grade: Grade,

    /// Индекс записи в Raft-журнале. Препятствует затиранию
    /// более старыми записями по мере применения Raft-журнала.
    commit_index: RaftIndex,
}
```

Цель такого запроса сводится к добавлению нового инстанса в Raft-группу. Для этого алгоритма справедливы следующие тезисы:

- `JoinRequest` отправляет всегда неинициализированный инстанс.
- В зависимости от того, содержится ли в запросе `instance_id`, проводится анализ его корректности (уникальности).
- В процессе обработки запроса в Raft-журнал добавляется запись `op::PersistPeer{ peer }`, который помимо всевозможных ID содержит поля `current_grade: 0_Offline`, `target_grade: 50_Online`, которые играют важную роль в обеспечении надежности кластера.
- Обработка запроса также включает в себя добавление инстанса в Raft-группу в роли `Learner` (процедура также известная как `raft::ConfChangeV2`). Raft не позволяет изменять топологию, пока предыдущее изменение не было применено. Поэтому в целях оптимизации обработка идет в отдельном потоке (т.н. `raft_conf_change_loop`) и выполняется группами.
- Прежде чем отвечать на запрос, инстанс дожидается применения изменений конфигурации. Это произойдет после того как он выйдет из состояния `joint state` ([подробнее](https://web.stanford.edu/~ouster/cgi-bin/papers/OngaroPhD.pdf), §4.3). <!-- [TODO](## "этот тезис в коде пока не реализован") -->
- В ответ выдается всегда новый `raft_id`, никому другому ранее не принадлежавший.
- Генерировать значение `raft_id` может только лидер Raft-группы. Ожидание `ConfChangeV2` лидерства не требует.
- Помимо всевозможных идентификаторов, ответ содержит список голосующих членов Raft-группы. Они понадобятся новому инстансу для того чтобы знать адреса соседей и общаться с ними.
- Также ответ содержит параметр `box_replication`, который требуется для правильной настройки репликации.

## Логика raft_conf_change_loop

Все узлы Raft в кластере делятся на два типа: голосующие (`voter`) и неголосующие (`learner`). На каждом инстансе кластера присутствует поток, управляющий конфигурацией Raft-группы (составом `voters` / `learners`). Реальные изменения тем не менее может генерировать только лидер, на остальных инстансах этот поток спит и ничего не делает.

Поток представляет собой бесконечный цикл. На каждой итерации выполняется проверка, что состав `voters` / `learners` соответствует состоянию инстансов, и при необходимости эти изменения группируются для записи в Raft-журнал:

- Инстансы с `target_grade: 50_Online` добавляются как неголосующие.
- Если есть возможность, инстансы в состоянии `Offline`передают право голоса инстансам в состоянии `Online`.<!--  [TODO](## "Сейчас offline инстанс демоутится безусловно, даже если других онлайн кандидатов нет. Не надо так делать.") -->
- Если общее количество голосующих инстансов оказывается меньше целевого, `Online`-инстансы получают право голоса.

Количество голосующих узлов в кластере не настраивается и зависит только от общего количества инстансов. Если инстансов 1 или 2, то голосующий узел один. <!--[TODO](## "Сейчас в кластере из 2 инстансов оба делаются голосующими. Надо проработать аргументацию и решить как правильно.").--> Если инстансов 3 или 4, то таких узлов три. Для кластера с 5 или более инстансами — пять голосующих узлов. Таким образом, даже в больших и очень больших кластерах достаточно иметь 5 голосующих узлов. Это поддерживает одновременно и живучесть кластера, и высокую скорость применения изменений в его конфигурации.


## Обработка записей Raft-журнала

Последовательность состояний каждой отдельной записи в Raft-журнале можно описать так:

```md
`Persisted` → `Committed` → `Applied`
```

При добавлении в журнал (по правилам это делает лидер) запись получает статус `Persisted` и начинает реплицироваться (это асинхронно делает файбер `raft_main_loop` ). Когда кворум узлов подтверждает персистентность записи, она считается зафиксированной. Важно понимать, что статус `Committed` присваевается записи на основе совокупности полученной информации, а не какого-то конкретного действия.

 Конкретные действия по обработке той или иной записи выполняет отдельный поток `raft_applier`<!--([TODO](## "Пока что отдельного потока нет, но лучше бы был"))-->. Для каждой записи он выполняет обработчик `Op::on_commit()` и по завершении присваивает записи статус `Applied`. Важно помнить, что обновление статуса и сама операция могут выполняться не атомарно (если в `Op::on_commit()` происходит передача управления другому потоку — yield). В таком случае, следует позаботиться хотя бы об идемпотентности операции. 

Схема ниже иллюстрирует эту информацию.

![Raft log](raft_log_curves.svg "Последовательность обработки записей в Raft-журнале")

Стоит также помнить, что алгоритм Raft гарантирует лишь консистентность последовательности записей, но не конкретные сроки выполнения. Смена статусов на разных инстансах так или иначе происходит в разные моменты времени, и иногда эту очередность приходится учитывать в алгоритмах. Например, при корректном запланированном выводе инстанса из строя (graceful shutdown) может возникнуть ситуация, когда инстанс завершится слишком быстро, и его соседи могут ошибочно продолжать считать его голосующим, что приведет к потере кворума. Ниже данная ситуаяи рассмотрена подробнее

<!-- Была у нас однажды такая история — шла разработка graceful shutdown. Тест (`test_joining.py::test_deactivation`) останавливал один из двух инстансов и проверял, что тот (назовем его i2) перестал быть голосующим. Иногда тест проходил нормально, но иногда падал — `i2` завершал работу раньше, чем `i1` получал от него подтверждение. При этом критерий остановки включал в себя ожидание коммита, но только локально на `i2`, а не на `i1`. Из-за этого `i1` терял кворум. -->


## Корректное завершение работы инстансы (graceful shutdown)

Чтобы выключение прошло штатно и не имело негативных последствий, необходимо следить за соблюдением следующих условий:

- Инстанс не должен оставаться голосующим, пока есть другие кандидаты в состоянии `Online`.
- Инстанс не должен оставаться лидером.

Чтобы этого добиться, каждый инстанс при срабатывании триггера `on_shutdown` отправляет лидеру запрос `UpdatePeerRequest{ target_grade: 0_Offline, graceful: true }`. Непосредственно изменением роли `voter` -> `learner` занимается отдельный поток на лидере (`raft_conf_change_loop`), инстанс только дожидается его применения.

## Описание уровней (grades) кластера

В отличие от других кластерных решений (например, того же Tarantool Cartridge) Picodata не использует понятие "состояния" для описания отдельных инстансов.
Вместо этого теперь применяется новое понятие «грейд» (grade). Данный термин отражает не состояние самого инстанса, а конфигурацию остальных участников кластера по отношению к нему. Существуют две разновидности грейдов: текущий (`current_grade`) и целевой (`target_grade`). 
Инициировать изменение `current_grade` может только лидер при поддержке кворума, что гарантирует консистентность принятого решения (и поддерживает доверие к системе в плане отказоустойчивости).

Инициировать изменение `target_grade` может кто угодно — это может быть сам инстанс (при его добавлении), или администратор кластера командой `picodata expel` либо нажатием Ctrl+C на клавиатуре. `target_grade` — это желаемое состояние инстанса, в которое тот должен прийти.

Приведением действительного к желаемому занимается специальный файбер на лидере — `topology_governor` («губернатор»). Он управляет всеми инстансами сразу.

На основе совокупности грейдов `topology_governor` на каждой итерации бесконечного цикла генерирует активности (activity) и пытается их организовать. Пока не организует, никаких других изменений в текущих грейдах не произойдет (но могут измениться целевые). Если активности завершатся ошибкой, то на следующей итерации они будут перевычислены с учетом новых целей.

Схема ниже показывает возможные грейды и варианты перехода между ними.

![Instance states](fsm.svg "Возможные переходы состояний инстанса")

Ниже перечислены существующие варианты активностей, которые создает `topology_governor`.

### 1. Обновить состав голосующих и неголосующиз узлов

Для этого требуется сгенерировать `ConfChangeV2`. Если он пустой, переходим к следующему шагу. Нет — отправляем его в Raft. Если не получилось — начинаем новую итерацию и перевычисляем активности. Получилось — ждем события `JointStateLeave`.

### 2. Обработать target_grade 0_Offline и 60_Expelled.

По большей части, активности сводятся к удалению инстанса из состава голосующизх узлов. Этот шаг уже пройден, поэтому всех желающих стать `0_Offline` можно сразу обновлять. Для `target_grade: 60_Expelled` требуется также подчистить `box.space.cluster` у его оставшихся реплик. Также, если это последний узел с ролью `storage` в репликасете, ему надо выставить вес 0. Дожидаться ребалансировки на этом шаге не требуется (да и не получится — слишком долгая блокировка), для этого есть отдельный пункт.

### 3. Выдвинуть 0_Offline в 10_RaftSynced

Операция выполняется для одного инстанса за раз (потом ее можно будет распараллелить). Чтобы это произошло, достаточно взять текущий `commit_index` на лидере и дождаться, пока выбранный инстанс его к себе применит. Как только это произошло, инстансу можно присваивать 10 грейд.

### 4. Выдвинуть 10_RaftSynced в 20_BoxSynced

Данная активность включает в себя выполнение `box.cfg({replication})` на всех инстансах выбранного репликасета. Перед выполнением все инстансы дожидаются применения `commit_index`, который сообщит им лидер. При успешном результате так можно выдвинуть сразу несколько инстансов.

### 5. Выдвинуть 20_BoxSynced в 30_VshardInitialized

<!-- Это уже веселее.-->Эта активность выполняется на всем кластере. В первую очередь надо проверить, всем ли репликасетам назначено хоть какое-то значение `vshard_weight`. Если нет — проставить 0 и дождаться коммита. По итогу надо убедиться, что все инстансы выполнили `vshard.router.cfg()` и `vshard.storage.cfg()`. Как и в предыдущем случае, грейд дается нескольким инстансам сразу. 

### 6. Выдвинуть 30_VshardInitialized в 50_Online

Данная активность аналогична предыдущей, только `vshard_weight` должен быть 1. Потом необходимо нужно еще раз убедиться, что все инстансы в кластере выполнили `vshard.router.cfg()` и `vshard.storage.cfg()`.

### 7. Вернуть к 60_Expelled

Наименьший приоритет имеет активность, связанная с ожиданием окончания ребалансировки. В конце концов, инстанс должен быть удален из `box.space.cluster` на всех оставшихся репликах, а также из `vshard.router.cfg` и `vshard.storage.cfg` на всем кластере.

Кластер Picodata поддерживает распределенные SQL-запросы. Подробнее о работающих кластерных функциях SQL см. в разделе [Возможности кластерного SQL](../sql_support).
