variables:
  BASE_IMAGE_NAME: $CI_REGISTRY_IMAGE
  BASE_IMAGE_TAG: $CI_COMMIT_SHA
  DOCKER_AUTH_CONFIG: $DOCKER_AUTH_RO

workflow:
  # See https://docs.gitlab.com/ee/ci/jobs/job_control.html#avoid-duplicate-pipelines
  rules:
    # To avoid duplicate pipelines we disable merge request events,
    # leaving only pushes and manual triggering.
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: never
    - if: $CI_PIPELINE_SOURCE == "push"
    - if: $CI_PIPELINE_SOURCE == "web"

default:
  image:
    name: docker-public.binary.picodata.io/kaniko-project/executor:v1.14.0-debug
    entrypoint: ['']
    pull_policy: [if-not-present]
  tags:
    - docker

stages:
  - build-base-image
  - lint
  - pack-doc
  - upload
  - deploy

build-base-image:
  stage: build-base-image
  variables:
    DOCKERFILE: "Dockerfile"
    PUSH_DOCKER: ""
    GIT_USERNAME: $CI_REGISTRY_USER
    GIT_PASSWORD: $CI_REGISTRY_PASSWORD
  script:
    - echo "Build picodata doc..."
    - cd docker/static
    - >
      /kaniko/executor --context $CI_PROJECT_DIR --dockerfile ${DOCKERFILE}
      --build-arg COMMIT_HASH=${CI_COMMIT_SHA} ${PUSH_DOCKER}
      --cache=false --cache-run-layers=true --single-snapshot --compressed-caching=false --use-new-run --snapshot-mode=redo --cleanup
      --destination ${BASE_IMAGE_NAME}:${BASE_IMAGE_TAG}

lint:
  image: ${BASE_IMAGE_NAME}:${BASE_IMAGE_TAG}
  stage: lint
  script:
    - echo "Checking picodata doc..."
    - make lint
    - echo "Picodata doc successfully checked"

pack-doc:
  image: ${BASE_IMAGE_NAME}:${BASE_IMAGE_TAG}
  stage: pack-doc
  script:
    - echo "Pack picodata doc..."
    - VER=$(date +%Y%m%d%H%M%S)
    - FNAME="picodata-doc-${VER}-${CI_COMMIT_REF_SLUG}.tgz"
    - echo "FNAME=$FNAME" | tee .vars
    - mkdocs build -d site --strict
    - pushd site
    - tar -cvzf ../$FNAME ./
    - popd
    - echo "Picodata doc successfully packed."
  cache:
    - key: $CI_COMMIT_REF_SLUG-vars
      paths:
        - .vars
      policy: push
    - key: $CI_COMMIT_REF_SLUG-tgz
      paths:
        - picodata-doc-*.tgz
      policy: push

upload-doc-to-binary:
  image: curlimages/curl
  stage: upload
  script:
    - echo "Upload picodata doc to binary..."
    - source .vars
    - echo "FNAME=$FNAME"
    - 'curl --fail -H "Authorization: Basic ${WWW_RAW_RW}" --upload-file $FNAME https://binary.picodata.io/repository/www-raw/$FNAME'
    - echo "Picodata doc successfully uploaded to binary."
  cache:
    - key: $CI_COMMIT_REF_SLUG-vars
      paths:
        - .vars
      policy: pull
    - key: $CI_COMMIT_REF_SLUG-tgz
      paths:
        - picodata-doc-*.tgz
      policy: pull

.deploy:
  variables:
    STAGE: TEST
  image: curlimages/curl
  stage: deploy
  script:
    - echo "Deploying picodata doc with branch $CI_COMMIT_BRANCH on $STAGE..."
    - source .vars
    - echo "FNAME=$FNAME"
    - echo "EXTRA_ARGS=$EXTRA_ARGS"
    - 'curl -X POST --fail -F token=$PIPELINE_TOKEN -F ref=main -F "variables[STAGE]=$STAGE" -F "variables[PICODATA_DOC]=$FNAME" $EXTRA_ARGS https://git.picodata.io/api/v4/projects/46/trigger/pipeline'
    # https://git.picodata.io/picodata/web-site/infra
    - echo "Picodata doc successfully deployed"
  cache:
    - key: $CI_COMMIT_REF_SLUG-vars
      paths:
        - .vars
      policy: pull

deploy-doc-to-test-main:
  extends:
    - .deploy
  rules:
    - if: $CI_COMMIT_BRANCH ==  $CI_DEFAULT_BRANCH

deploy-doc-to-test-devbranch:
  extends:
    - .deploy
  rules:
    - if: $CI_COMMIT_BRANCH !=  $CI_DEFAULT_BRANCH
      when: manual
  allow_failure: true
  variables:
    EXTRA_ARGS: '-F variables[PICODATA_DOC_SUBDIR]=branch-${CI_COMMIT_BRANCH}'

deploy-doc-to-prod:
  extends:
    - .deploy
  rules:
    - if: $CI_COMMIT_BRANCH ==  $CI_DEFAULT_BRANCH
  variables:
    STAGE: PROD
